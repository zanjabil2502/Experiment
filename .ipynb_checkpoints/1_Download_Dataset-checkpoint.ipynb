{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TLVeX4JFVq9F"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa \n",
    "import librosa.display\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SYfja4naeas9"
   },
   "source": [
    "# 1-Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Folder Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('dataset')==False:\n",
    "    os.mkdir('dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-kR2CxYJcCzz"
   },
   "source": [
    "## Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd dataset/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Coswara Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PteAAgv6btxi",
    "outputId": "4cd2a897-8e38-44f3-dd9c-fe0f0821127f"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/iiscleap/Coswara-Data.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Coswara Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DQjUs7MScCyX",
    "outputId": "6e4cfd74-2135-47a4-b360-993663951007"
   },
   "outputs": [],
   "source": [
    "rt_dir = 'Coswara-Data/'\n",
    "import glob\n",
    "for each in os.listdir(rt_dir):\n",
    "    if os.path.isdir(os.path.join(rt_dir,each)) and each != '.git':\n",
    "        print(each)\n",
    "        !cat {os.path.join(rt_dir, each,'')}*.tar.gz.* > {os.path.join(rt_dir, each,'')}combined_file.tar.gz\n",
    "        !tar -xzf {os.path.join(rt_dir, each,'')}combined_file.tar.gz -C {rt_dir}\n",
    "subset = glob.glob('Coswara-Data/*/*.tar.gz.*') + glob.glob('Coswara-Data/*/combined_data.tar.gz')\n",
    "[os.remove(x) for x in subset];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Coughvid Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://zenodo.org/record/4048312/files/public_dataset.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Coughvid Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('Coughvid-Data')==False:\n",
    "    os.mkdir('Coughvid-Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ItIYcUjHgi9z",
    "outputId": "40903f9b-cb28-472a-f5ef-c372f63b649e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!unzip \"public_dataset.zip\" -d \"Coughvid-Data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 214
    },
    "id": "wsLmzEc9l65j",
    "outputId": "d5327fa2-6e18-47c7-c1a1-b191aaa759c7"
   },
   "outputs": [],
   "source": [
    "names   = ['ID','Fever/MP','ORC','STATUS','DIR','DataSet']\n",
    "join_by = pd.read_csv('Coswara-Data/combined_data.csv')\n",
    "\n",
    "import glob\n",
    "df_list = []\n",
    "for path in tqdm(glob.glob('Coswara-Data/*/*/cough-shallow.wav')):\n",
    "  temp = pd.DataFrame(columns=['id','DIR'])\n",
    "  temp['id'] = [path.split('/')[-2]]\n",
    "  temp['DIR'] = [path]\n",
    "  temp = pd.merge(left=temp,right=join_by,on='id',how='inner')\n",
    "\n",
    "  temp['fomp']= (temp['fever']| temp['mp']).apply(int)\n",
    "  temp['oths']= (temp['cld']|temp['asthma']|temp['cold']|temp['st']|temp['pneumonia']).apply(int)\n",
    "  temp        = temp[['id','covid_status','DIR','fomp','oths']]\n",
    "  df_list.append(temp.rename(columns={'id':'ID','covid_status':'STATUS','DIR':'DIR','fomp':'Fever/MP','oths':'ORC'}))\n",
    "CosData=pd.concat(df_list)\n",
    "CosData['DataSet'] = 'coswara'\n",
    "CosData   = CosData.sample(frac=1).reset_index(drop=True)\n",
    "CosData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CosData.to_csv('Coswara_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CosData = pd.read_csv('Coswara_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IWd7TgddcLCi"
   },
   "source": [
    "## Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('image/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "id": "vhG5icIXtP9R",
    "outputId": "06712e4b-3198-40c6-9c5e-1ca281191880"
   },
   "outputs": [],
   "source": [
    "coughvid  = 'public_dataset/'\n",
    "\n",
    "VidData   = pd.read_csv(os.path.join(coughvid,'metadata_compiled.csv'),header=0)\n",
    "VidData   = VidData.loc[VidData['cough_detected'] >= 0.9][['uuid','fever_muscle_pain','respiratory_condition','status']]\n",
    "VidData.dropna(inplace=True)\n",
    "\n",
    "extradata = VidData.loc[VidData['status']=='COVID-19']\n",
    "notradata = VidData.loc[VidData['status']!='COVID-19'][0:1000]\n",
    "\n",
    "TotData   = pd.concat([extradata,notradata],ignore_index= True)\n",
    "TotData['DIR'] = coughvid + TotData['uuid'] + '.webm'\n",
    "TotData['DataSet'] = 'coughvid'\n",
    "TotData['fever_muscle_pain']    = TotData['fever_muscle_pain'].apply(int)\n",
    "TotData['respiratory_condition']= TotData['respiratory_condition'].apply(int)\n",
    "TotData   = pd.concat([CosData,TotData.rename(columns={'uuid':'ID','status':'STATUS','fever_muscle_pain':'Fever/MP','respiratory_condition':'ORC'})])\n",
    "TotData   = TotData.sample(frac=1).reset_index(drop=True)\n",
    "TotData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TotData.to_csv('Total_Dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TotData = pd.read_csv('Total_Dataset.csv')\n",
    "TotData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare  = 'ComParE2021-CCS-CSS-Data/dist/wav/'\n",
    "join_by = pd.read_csv('ComParE2021-CCS-CSS-Data/metaData_CCS.csv')\n",
    "\n",
    "df_list = []\n",
    "for i in tqdm(os.listdir(compare)):\n",
    "    temp = pd.DataFrame(columns=['filename','DIR'])\n",
    "    temp['filename'] = [i]\n",
    "    temp['DIR'] = [compare+i]\n",
    "    temp = pd.merge(left=temp,right=join_by,on='filename',how='inner')\n",
    "\n",
    "    temp        = temp[['Uid','label','DIR']]\n",
    "    df_list.append(temp.rename(columns={'Uid':'ID','label':'STATUS','DIR':'DIR'}))\n",
    "ComData=pd.concat(df_list)\n",
    "ComData['DataSet'] = 'compare'\n",
    "ComData.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FullData = pd.concat([ComData, TotData])\n",
    "FullData = FullData[['ID','STATUS','DIR','DataSet']]\n",
    "FullData  = FullData.sample(frac=1).reset_index(drop=True)\n",
    "FullData.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FullData.to_csv('Merge_Dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diag = []\n",
    "for f in FullData['STATUS']:\n",
    "    diag.append(f)\n",
    "key = list(dict.fromkeys(diag))\n",
    "print(key) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "for index, row in FullData.iterrows():\n",
    "    temp = pd.DataFrame(columns=['ID','STATUS','DIR','DataSet'])\n",
    "    diagnose = row['STATUS']\n",
    "    if diagnose == 'healthy' or diagnose == 'negative':\n",
    "        status = 'negative'\n",
    "        temp['ID'] = [row['ID']]\n",
    "        temp['STATUS'] = [status]\n",
    "        temp['DIR'] = [row['DIR']]\n",
    "        temp['DataSet'] = [row['DataSet']] \n",
    "    elif diagnose == 'positive_mild' or diagnose == 'positive_moderate' or diagnose == 'positive' or diagnose == 'COVID-19':\n",
    "        status = 'positive'\n",
    "        temp['ID'] = [row['ID']]\n",
    "        temp['STATUS'] = [status]\n",
    "        temp['DIR'] = [row['DIR']]\n",
    "        temp['DataSet'] = [row['DataSet']]\n",
    "    df_list.append(temp)\n",
    "CovidData=pd.concat(df_list)\n",
    "CovidData = CovidData.sample(frac=1).reset_index(drop=True)\n",
    "CovidData.head()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CovidData.to_csv('Covid_Dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CovidData = pd.read_csv('Covid_Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "for index, row in CovidData.iterrows():\n",
    "    temp = pd.DataFrame(columns=['STATUS','DIR','DataSet'])\n",
    "    diagnose = row['STATUS']\n",
    "    dirs = row['DIR']\n",
    "    filename = dirs.split('/')\n",
    "    if diagnose == 'healthy' or diagnose == 'negative':\n",
    "        status = 'negative'\n",
    "        temp['ID'] = [row['ID']]\n",
    "        temp['STATUS'] = [status]\n",
    "        temp['DIR'] = [row['DIR']]\n",
    "        temp['DataSet'] = [row['DataSet']] \n",
    "    elif diagnose == 'positive_mild' or diagnose == 'positive_moderate' or diagnose == 'positive' or diagnose == 'COVID-19':\n",
    "        status = 'positive'\n",
    "        temp['ID'] = [row['ID']]\n",
    "        temp['STATUS'] = [status]\n",
    "        temp['DIR'] = [row['DIR']]\n",
    "        temp['DataSet'] = [row['DataSet']]\n",
    "    df_list.append(temp)\n",
    "CovidData=pd.concat(df_list)\n",
    "CovidData = CovidData.sample(frac=1).reset_index(drop=True)\n",
    "CovidData.head()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "for index, row in tqdm(CovidData.iterrows()):\n",
    "    temp = pd.DataFrame(columns=['STATUS','DIR','DataSet'])\n",
    "    diagnose = row['STATUS']\n",
    "    dirs = row['DIR']\n",
    "    dataset = row['DataSet']\n",
    "    filename = dirs.split('/')[-1].split('.')[0].split('_')[0]\n",
    "    if filename == 'test':\n",
    "        #print(filename)\n",
    "        temp['STATUS'] = [row['STATUS']]\n",
    "        temp['DIR'] = [row['DIR']]\n",
    "        temp['DataSet'] = [dataset]\n",
    "    df_list.append(temp)\n",
    "    \n",
    "TestData = pd.concat(df_list)\n",
    "TestData = TestData.sample(frac=1).reset_index(drop=True)\n",
    "TestData.head(20)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestData.to_csv('Test_Dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "for index, row in tqdm(CovidData.iterrows()):\n",
    "    temp = pd.DataFrame(columns=['STATUS','DIR','DataSet','ID'])\n",
    "    diagnose = row['STATUS']\n",
    "    dirs = row['DIR']\n",
    "    dataset = row['DataSet']\n",
    "    data = row['ID']\n",
    "    filename = dirs.split('/')[-1].split('.')[0].split('_')[0]\n",
    "    if filename != 'test' and filename != 'devel':\n",
    "        #print(filename)\n",
    "        temp['STATUS'] = [row['STATUS']]\n",
    "        temp['DIR'] = [row['DIR']]\n",
    "        temp['DataSet'] = [dataset]\n",
    "        temp['ID'] = [data]\n",
    "    df_list.append(temp)\n",
    "    \n",
    "TrainData = pd.concat(df_list)\n",
    "TrainData = TrainData.sample(frac=1).reset_index(drop=True)\n",
    "TrainData.head(20)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list=[]\n",
    "for index,row in tqdm(TrainData.iterrows()):\n",
    "    temp = pd.DataFrame(columns=['filename','label'])\n",
    "    diagnose = row['STATUS']\n",
    "    dirs = row['DIR']\n",
    "    dataset = row['DataSet']\n",
    "    name = row['ID']\n",
    "    filename = dirs.split('/')[-1]\n",
    "    if dataset == 'coswara':\n",
    "        fn = name+'.wav'\n",
    "        temp['label'] = [row['STATUS']]\n",
    "        temp['filename'] = [fn]\n",
    "    elif dataset == 'coughvid':\n",
    "        fn = name+'.wav'\n",
    "        temp['label'] = [row['STATUS']]\n",
    "        temp['filename'] = [fn]\n",
    "    else:\n",
    "        temp['label'] = [row['STATUS']]\n",
    "        temp['filename'] = [dirs.split('/')[-1]]\n",
    "    \n",
    "        df_list.append(temp)\n",
    "    \n",
    "Train = pd.concat(df_list)\n",
    "Train = Train.sample(frac=1).reset_index(drop=True)\n",
    "Train.head(20)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train.to_csv('train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "for index, row in tqdm(CovidData.iterrows()):\n",
    "    temp = pd.DataFrame(columns=['filename','label'])\n",
    "    diagnose = row['STATUS']\n",
    "    dirs = row['DIR']\n",
    "    dataset = row['DataSet']\n",
    "    filename = dirs.split('/')[-1].split('.')[0].split('_')[0]\n",
    "    if filename != 'test' and filename != 'devel':\n",
    "        #print(filename)\n",
    "        temp['label'] = [row['STATUS']]\n",
    "        temp['filename'] = [dirs.split('/')[-1].split('.')[0]]\n",
    "    df_list.append(temp)\n",
    "    \n",
    "TrainData = pd.concat(df_list)\n",
    "TrainData = TrainData.sample(frac=1).reset_index(drop=True)\n",
    "TrainData.head(20)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "for index, row in tqdm(CovidData.iterrows()):\n",
    "    temp = pd.DataFrame(columns=['filename','label', 'dir'])\n",
    "    diagnose = row['STATUS']\n",
    "    dirs = row['DIR']\n",
    "    dataset = row['DataSet']\n",
    "    filename = dirs.split('/')[-1].split('.')[0].split('_')[0]\n",
    "    if filename != 'test' and filename != 'devel' and filename != 'train':\n",
    "        #print(filename)\n",
    "        temp['label'] = [row['STATUS']]\n",
    "        temp['filename'] = [dirs.split('/')[-1]]\n",
    "        temp['dir'] = [dirs]\n",
    "    df_list.append(temp)\n",
    "    \n",
    "TrainData = pd.concat(df_list)\n",
    "TrainData = TrainData.sample(frac=1).reset_index(drop=True)\n",
    "TrainData.head(20)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in tqdm(TrainData.iterrows()):\n",
    "    source = row['dir']\n",
    "    num = row['filename']\n",
    "    path = os.path.join('SPIRA-ComParE2021 (copy)/Tosse/dist/wav_normalized',num)\n",
    "    if os.path.exists(source) == True:\n",
    "        shutil.copyfile(source,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "for index, row in tqdm(CovidData.iterrows()):\n",
    "    temp = pd.DataFrame(columns=['filename','label'])\n",
    "    diagnose = row['STATUS']\n",
    "    dirs = row['DIR']\n",
    "    dataset = row['DataSet']\n",
    "    filename = dirs.split('/')[-1].split('.')[0].split('_')[0]\n",
    "    if os.path.exists(dirs) == True :\n",
    "        if filename != 'test' and filename != 'devel':\n",
    "            #print(filename)\n",
    "            temp['label'] = [row['STATUS']]\n",
    "            temp['filename'] = [dirs.split('/')[-1]]\n",
    "    df_list.append(temp)\n",
    "    \n",
    "TrainData = pd.concat(df_list)\n",
    "TrainData = TrainData.sample(frac=1).reset_index(drop=True)\n",
    "TrainData.head(20)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainData.to_csv('train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ffmpeg -i 'public_dataset/63f4e572-e693-4265-8b77-07f552fc63e9.webm' -c:a pcm_f32le 'out.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ffmpeg-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in tqdm(TrainData.iterrows()):\n",
    "    source = row['DIR']\n",
    "    #num = row['filename']\n",
    "    data = row['ID']\n",
    "    path = os.path.join('SPIRA-ComParE2021 (copy)/Tosse/dist/wav_normalized',data+'.wav')\n",
    "    if os.path.exists(source) == True:\n",
    "        if (source.endswith(\".webm\")):\n",
    "            command = f\"ffmpeg -i ' {source} -c:a pcm_f32le {path}\"\n",
    "            print(command)\n",
    "            os.system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DNN_Dec20.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
